{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# option + shift + f to format\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# option + shift + o to organise imports\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# dpb.set_trace() to set trace for debugging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m data_path = Path(\u001b[34;43m__file__\u001b[39;49m).parent.parent / \u001b[33m\"\u001b[39m\u001b[33mEEG_data\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m data_path.exists(), \u001b[33m\"\u001b[39m\u001b[33mData path does not exist\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m dirs = os.listdir(data_path / \u001b[33m\"\u001b[39m\u001b[33mds005207\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pdb\n",
    "from pathlib import Path\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# option + shift + f to format\n",
    "# option + shift + o to organise imports\n",
    "# dpb.set_trace() to set trace for debugging\n",
    "\n",
    "\n",
    "\n",
    "data_path = Path('../') / \"EEG_data\"\n",
    "\n",
    "assert data_path.exists(), \"Data path does not exist\"\n",
    "\n",
    "dirs = os.listdir(data_path / \"ds005207\")\n",
    "subs = [d for d in dirs if d.startswith(\"sub\")]\n",
    "\n",
    "df_channels = pd.DataFrame()\n",
    "\n",
    "for sub in subs:\n",
    "    sub_root = data_path / \"ds005207\" / sub / \"ses-001\" / \"eeg\"\n",
    "    eeg_file = sub_root / f\"{sub}_ses-001_task-sleep_acq-PSG_eeg.set\"\n",
    "    scoring_fname = sub_root / f\"{sub}_ses-001_task-sleep_acq-PSGScoring_events.tsv\"\n",
    "    mapping_fname = (\n",
    "        data_path / \"ds005207\" / \"task-sleep_acq-cEEGridScoring_events.json\"\n",
    "    )\n",
    "    # Make output path folder and check that it didnt fail quietly\n",
    "    output_path = Path(__file__).parent.parent / \"EEG_data\" / \"cleaned_data\"\n",
    "    try:\n",
    "        os.mkdir(output_path)\n",
    "    except FileExistsError:\n",
    "        print(f\"Directory '{output_path}' failed\")\n",
    "\n",
    " \n",
    "\n",
    "    # Error checking to make sure the file paths exist\n",
    "    assert sub_root.exists(), \"Subject root does not exist\"\n",
    "    assert eeg_file.exists(), \"EEG file file does not exist\"\n",
    "    assert scoring_fname.exists(), \"Secoring file does not exist\"\n",
    "    assert mapping_fname.exists(), \"Mapping file does not exist\"\n",
    "    assert output_path.exists(), \"Output file does not exist\"\n",
    "\n",
    "    # --------------------------------\n",
    "    # --- Main Proccessing of Data ---\n",
    "    # --------------------------------\n",
    "\n",
    "    raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)\n",
    "\n",
    "    with open(mapping_fname, \"r\") as f:\n",
    "        eeg_json = json.load(f)\n",
    "\n",
    "    sleep_stage_mapping = eeg_json[\"staging\"][\"Levels\"]\n",
    "\n",
    "    scoring_df = pd.read_csv(scoring_fname, sep=\"\\t\")\n",
    "\n",
    "    onsets = scoring_df[\"onset\"].to_numpy()\n",
    "    durations = np.full(len(scoring_df), 30)\n",
    "    descriptions = (\n",
    "        scoring_df[\"staging\"].map(str).map(sleep_stage_mapping).to_numpy()\n",
    "    )\n",
    "\n",
    "    annotations = mne.Annotations(\n",
    "        onset=onsets, duration=durations, description=descriptions\n",
    "    )\n",
    "\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    events, event_id = mne.events_from_annotations(raw, event_id=None)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Channels in raw data\", sub, \"with names \", raw.ch_names)\n",
    "    \n",
    "    # #Piece of code that removes a ll but the EEG data \n",
    "    # #'F4:A1', 'C4:A1', 'O1:A2', \n",
    "    # channels_to_keep = [\n",
    "    # 'F4:M1', 'C4:M1', 'O1:M2', \n",
    "    # 'F3:M2', 'C3:M2', 'O2:M1'\n",
    "\n",
    "\n",
    "\n",
    "    # --------------------------------\n",
    "    # ---- Actual Data Cleaning  -----\n",
    "    # --------------------------------\n",
    "\n",
    "    # Band and notch filter applied\n",
    "    raw.filter(l_freq=0.5, h_freq=100, fir_design=\"firwin\",verbose = False)\n",
    "    raw.notch_filter(freqs=50, fir_design=\"firwin\", verbose = False)\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # ---- Parititioning cleaned data into 30 sec Epoch Objects  -----\n",
    "    # ----------------------------------------------------------------\n",
    "    epochs = mne.Epochs(\n",
    "        raw=raw,\n",
    "        events=events,\n",
    "        event_id=event_id,\n",
    "        tmin=0,\n",
    "        tmax=30,\n",
    "        preload=True, \n",
    "        baseline=None,\n",
    "    )\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    cleaned_epochs_fname = os.path.join(output_path, f\"{sub}_cleaned-epo.fif\")\n",
    "    epochs.save(cleaned_epochs_fname, overwrite=True)\n",
    "\n",
    "\n",
    "    df_channels\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scif2001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
